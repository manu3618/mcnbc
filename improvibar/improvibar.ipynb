{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shop results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## goal\n",
    "\n",
    "* find factors influencing this shop's results\n",
    "* predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, time\n",
    "from os import path, scandir\n",
    "\n",
    "daily_datadir = \"./data/CaisseJour/\"\n",
    "datadirs = [path.join(daily_datadir, d.name) for d in scandir(daily_datadir)]\n",
    "data_files = [\n",
    "    path.join(datadir, file.name) for datadir in datadirs for file in scandir(datadir)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_caisse(filename, keywords=(\"Chiffre\", \"TVA\", \"nombre\", \"moyen\", \"ticket\")):\n",
    "    \"\"\"Parse file \"caisse jour\"\n",
    "    \n",
    "    Args:\n",
    "        filename (string): file to parse\n",
    "        keywords (list): list of keywords for  one line data\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with open(filename, \"br\") as fd:\n",
    "        for line in fd:\n",
    "            line = line.decode(\"Windows-1252\", errors=\"ignore\")\n",
    "            if \"à\" in line:\n",
    "                # try with date\n",
    "                try:\n",
    "                    date = [int(d) for d in line.split(\" \")[0].split(\"/\")]\n",
    "                except ValueError:\n",
    "                    # \"à\" in cocktail name\n",
    "                    continue\n",
    "                data[\"date\"] = datetime(date[2], date[1], date[0])\n",
    "            elif any(keyword in line for keyword in keywords):\n",
    "                value = line.split(\";\")[1]\n",
    "                value = value.strip(\"€ \\r\\n\")\n",
    "                try:\n",
    "                    # parse french number representation\n",
    "                    value = value.replace(\",\", \".\")\n",
    "                    value = float(value)\n",
    "                except ValueError:\n",
    "                    # not a number, cannot convertto float\n",
    "                    pass\n",
    "                data[line.split(\";\")[0].strip()] = value\n",
    "        # TODO: add small tables\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = pd.DataFrame(parse_caisse(f) for f in data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.index = daily[\"date\"]  # keep date and index\n",
    "open_days = daily[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = min(daily[\"date\"])\n",
    "end_date = max(daily[\"date\"])\n",
    "\n",
    "# start_date = datetime(2018, 09, 01)\n",
    "# end_date = datetime(2019, 09, 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_monthweek(date):\n",
    "    \"\"\"Return the week number of the month, i.e. the number of mondays before this date.\n",
    "    \n",
    "    Args:\n",
    "        date: (datetime.datetime)\n",
    "        \n",
    "    Return:\n",
    "        int: the week number\n",
    "    \"\"\"\n",
    "    return len(\n",
    "        [\n",
    "            day\n",
    "            for day in pd.date_range(datetime(date.year, date.month, 1), date)\n",
    "            if day.weekday() == 0\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.DataFrame(pd.date_range(start_date, end_date), columns=(\"date\",))\n",
    "# calendar[\"day\", \"month\", \"year\", \"wod\"] = list(map(lambda x: (x.day, x.month, x.year, x.weekday()), calendar[\"date\"]))\n",
    "calendar[\"day\"] = list(map(lambda x: x.day, calendar[\"date\"]))\n",
    "calendar[\"month\"] = list(map(lambda x: x.month, calendar[\"date\"]))\n",
    "calendar[\"year\"] = list(map(lambda x: x.year, calendar[\"date\"]))\n",
    "calendar[\"dow\"] = list(map(lambda x: x.weekday(), calendar[\"date\"]))\n",
    "calendar[\"week number\"] = list(map(lambda x: x.isocalendar()[1], calendar[\"date\"]))\n",
    "calendar[\"month week number\"] = list(map(date_to_monthweek, calendar[\"date\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holidays\n",
    "\n",
    "from https://date.nager.at/PublicHoliday/DownloadCSV/FR/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./data/calendars\"\n",
    "data_files = [path.join(datadir, file.name) for file in scandir(datadir)]\n",
    "\n",
    "holidays = pd.concat([pd.read_csv(file) for file in data_files])\n",
    "\n",
    "# reformat date\n",
    "holidays[\"Date\"] = pd.Series(\n",
    "    [\n",
    "        datetime(int(x.split(\"-\")[0]), int(x.split(\"-\")[1]), int(x.split(\"-\")[2]))\n",
    "        for x in holidays[\"Date\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar[\"public holidays\"] = list(\n",
    "    map(lambda x: x in list(holidays[\"Date\"]), calendar[\"date\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = calendar.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pandas way\n",
    "daily = daily.join([calendar])\n",
    "\n",
    "# the spark.sql way\n",
    "# TODO\n",
    "\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather\n",
    "\n",
    "from meteofrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icalendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icalfile = \"./data/prog/Programmation.ics\"\n",
    "\n",
    "columns = (\"DTSTAMP\", \"UID\", \"SUMMARY\", \"DTSTART\", \"DTEND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(icalfile, \"rb\") as fd:\n",
    "    icalcontent = fd.read()\n",
    "\n",
    "events_cal = icalendar.Calendar().from_ical(icalcontent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.DataFrame()\n",
    "for evt in events_cal.walk(\"vevent\"):\n",
    "\n",
    "    # rebuild event\n",
    "    elt = {}\n",
    "    for k, v in dict(evt).items():\n",
    "        elt[k] = evt[k].to_ical().decode()\n",
    "    events = events.append(pd.DataFrame([elt]), sort=False)\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse date\n",
    "date_cols = [col for col in events.columns if col.startswith(\"DT\")]\n",
    "\n",
    "for col in date_cols:\n",
    "    events[col] = events[col].apply(pd.to_datetime)\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration are not all filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"DURATION\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[~events[\"DURATION\"].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[events[\"DTEND\"].isnull() & events[\"DURATION\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "either duration or end is filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dtend(row):\n",
    "    \"\"\"Return DTEND value\n",
    "    \"\"\"\n",
    "    if row[\"DTEND\"] not in (pd.NaT, np.NaN):\n",
    "        return row[\"DTEND\"]\n",
    "    dur = row[\"DURATION\"].strip(\"PTM\")\n",
    "    parsed = dur.split(\"H\")\n",
    "    hour = parsed[0]\n",
    "    minutes = parsed[1] if parsed[1] else \"0\"\n",
    "    return row[\"DTSTART\"] + timedelta(int(hour), int(minutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"DTEND\"] = events.apply(compute_dtend, axis=1)\n",
    "events[events[\"DTEND\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"DURATION\"] = events[\"DTEND\"] - events[\"DTSTART\"]\n",
    "events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"DATE\"] = events[\"DTSTART\"].apply(lambda x: x.date())\n",
    "events[\"START_TIME\"] = events[\"DTSTART\"].apply(lambda x: x.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./data/prog/type_spectacle.csv\", \"r\") as fd:\n",
    "    reader = csv.DictReader(fd)\n",
    "    type_spectacle = {\n",
    "        row[\"nom troupe\"]: row[\"type spectacle\"].lower() for row in reader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"TYPE\"] = events[\"SUMMARY\"].apply(lambda x: type_spectacle[x])\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"TYPE\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe and restrict features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data description\n",
    "columns_descr = {\n",
    "    \"Chiffre d'Affaires HT\": \"(float) Income (taxes excluded)\",\n",
    "    \"Chiffre d'Affaires TTC\": \"(float) Income (taxes included)\",\n",
    "    \"Nombre moyen de produits / Ticket\": \"(float) Mean good numbers per transaction\",\n",
    "    \"Ticket moyen TTC\": \"(float) Mean transaction value\",\n",
    "    \"date\": \"(date) date of the day\",\n",
    "    \"dow\": \"(int) day of week, 0..7\",\n",
    "    \"day\": \"(int) day in month\",\n",
    "    \"month\": \"(int) month number\",\n",
    "    \"week number\": \"(int) iso week number (0..53)\",\n",
    "    \"month week number\": \"(int) month week number (0..5)\",\n",
    "    \"year\": \" (int) year\",\n",
    "    \"public holidays\": \"(bool) Public holiday in France\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = columns_descr.keys()\n",
    "daily = daily.loc[:, columns_descr.keys()]\n",
    "daily[\"public holidays\"] = daily[\"public holidays\"].apply(\n",
    "    lambda x: 1 if x is True else 0\n",
    ")\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(daily.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are highly correlate features, some may be discarded. Moreover, some features are redondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del columns_descr[\"Chiffre d'Affaires HT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numeric features\n",
    "num_cols = [\n",
    "    col for col in columns_descr.keys() if np.isreal(daily.loc[start_date, col])\n",
    "]\n",
    "num_cols\n",
    "# scatter_matrix(daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(daily.loc[:, num_cols], figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * The Income seems to vary each month\n",
    " * There are outliers in income\n",
    " * Mean product per transaction and mean transaction number is highly correlated (as expected) except for some days (must be treated separately)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=daily, x=\"Ticket moyen TTC\", y=\"Nombre moyen de produits / Ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3 days with higher mean transaction\n",
    "* 1 day with the mean product price is higher than usual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to know if this outliers should be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.loc[daily[\"Ticket moyen TTC\"] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of this 3 outlier correspond to a privatisation. This individual will be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = daily.loc[daily[\"Ticket moyen TTC\"] < 60]\n",
    "# daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opening day should alsobe discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.loc[\"2018-09-08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = daily[daily[\"date\"] != \"2018-09-08\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Per  month income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (0, max(daily[\"Chiffre d'Affaires TTC\"]))\n",
    "for year, month in product(range(2018, 2020), range(1, 13)):\n",
    "    cur_data = daily.loc[(daily[\"month\"] == month) & (daily[\"year\"] == year)]\n",
    "    if len(cur_data) == 0:\n",
    "        continue\n",
    "    plt.figure()\n",
    "    # cur_data[\"Chiffre d'Affaires TTC\"].plot(kind=\"box\",)\n",
    "    cur_data[\"Chiffre d'Affaires TTC\"].plot(\n",
    "        kind=\"hist\", xlim=xlim, title=\"Income for {}/{}\".format(month, year), bins=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For almost all month, there is one and only one day with high income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily[daily[\"Chiffre d'Affaires TTC\"] > 1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each month, one event help raising the income:\n",
    "* 2018-09-08: opening\n",
    "* 2018-10-31: halloween\n",
    "* 2018-11-10: Nabla & JM\n",
    "* 2018-12-13: Christmas co-plateau\n",
    "* 2018-01-05: privatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, group in daily.groupby(\"dow\"):\n",
    "    plt.figure()\n",
    "    group[\"Chiffre d'Affaires TTC\"].plot(kind=\"hist\", title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = daily.loc[:, [\"dow\", \"Chiffre d'Affaires TTC\"]]\n",
    "t = t.groupby(\"dow\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.boxplot(column=\"Chiffre d'Affaires TTC\", by=\"dow\")\n",
    "daily.boxplot(column=\"Chiffre d'Affaires TTC\", by=\"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = daily.loc[:, [\"month\", \"Chiffre d'Affaires TTC\"]]\n",
    "t = t.groupby(\"month\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = daily.loc[:, [\"day\", \"Chiffre d'Affaires TTC\"]]\n",
    "t = t.groupby(\"day\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily[\"Chiffre d'Affaires TTC\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph denote weekly seasonalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = daily.loc[:, [\"month week number\", \"Chiffre d'Affaires TTC\"]]\n",
    "t = t.groupby(\"month week number\").describe()\n",
    "# t.plot(figsize=(15,7))\n",
    "# t.iloc[:, [4, 5, 6]].plot(figsize=(15,7))\n",
    "daily.boxplot(column=\"Chiffre d'Affaires TTC\", by=\"month week number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = daily.loc[:, [\"month week number\", \"dow\", \"Chiffre d'Affaires TTC\"]]\n",
    "t = t.groupby([\"month week number\", \"dow\"]).describe()\n",
    "\n",
    "# t.iloc[:, [4, 5, 6]].plot(figsize=(15,7))\n",
    "daily.boxplot(\n",
    "    column=\"Chiffre d'Affaires TTC\", by=[\"month week number\", \"dow\"], figsize=(15, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st friday after the 1st monday of each month is really a good day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from numpy.linalg import LinAlgError\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = daily[\"Chiffre d'Affaires TTC\"].resample(\"1D\").mean()\n",
    "t = t.interpolate()\n",
    "\n",
    "zeros = pd.Series(\n",
    "    0, index=[d for d in pd.date_range(start_date, end_date) if d not in open_days]\n",
    ")\n",
    "for day in zeros.index:\n",
    "    t[day] = 0\n",
    "\n",
    "cleaned_daily = t\n",
    "cleaned_daily.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_daily.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = pd.date_range(start_date, end_date, 5)[3]\n",
    "daily_X_train_test = pd.DataFrame(cleaned_daily)\n",
    "daily_X_train, daily_X_test = (\n",
    "    daily_X_train_test[daily_X_train_test.index < split_date],\n",
    "    daily_X_train_test[daily_X_train_test.index >= split_date],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(len(daily_X_train)).reshape(-1, 1)\n",
    "TREND_REG = LinearRegression().fit(index, daily_X_train)\n",
    "trend = TREND_REG.predict(index)\n",
    "trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_X_train[\"trend\"] = trend\n",
    "# daily_X_train[\"detrend\"] = cleaned_daily - trend\n",
    "daily_X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_X_train.plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend function for forecasts\n",
    "def forecast_trend(day1):\n",
    "    \"\"\" Return the trend part for the date day\n",
    "    \"\"\"\n",
    "    day0 = daily.index[0]\n",
    "    day0 = datetime(day0.year, day0.month, day0.day)\n",
    "    day1 = datetime(day1.year, day1.month, day1.day)\n",
    "    return TREND_REG.predict(np.array([(day1 - day0).days]).reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "forecast_trend(datetime.now().date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seasonalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = seasonal_decompose(daily_X_train)\n",
    "seasonal, trend, residual = seasons.seasonal, seasons.trend, seasons.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_X_train[\"auto trend\"] = trend[\"Chiffre d'Affaires TTC\"]\n",
    "daily_X_train[\"auto seasonals\"] = seasonal[\"Chiffre d'Affaires TTC\"]\n",
    "daily_X_train[\"auto residuals\"] = residual[\"Chiffre d'Affaires TTC\"]\n",
    "daily_X_train.plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is a weekly seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = daily_X_train.head(7).copy()\n",
    "ws[\"dow\"] = list(map(lambda x: x.weekday(), ws.index))\n",
    "WEEKLY_SEASON = dict(zip(ws[\"dow\"], ws[\"auto seasonals\"]))\n",
    "\n",
    "\n",
    "def forecast_seasonality(day):\n",
    "    \"\"\"Return the seasonality component\n",
    "    \"\"\"\n",
    "    return WEEKLY_SEASON[day.weekday()]\n",
    "\n",
    "\n",
    "forecast_seasonality(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_season = (\n",
    "    daily_X_train.copy()\n",
    "    .reset_index()[\"date\"]\n",
    "    .apply(lambda x: forecast_trend(x) + forecast_seasonality(x))\n",
    ")\n",
    "\n",
    "daily_X_train[\"trend + seasonal\"] = list(trend_season)\n",
    "daily_X_train.loc[:, [\"Chiffre d'Affaires TTC\", \"trend + seasonal\"]].plot(\n",
    "    figsize=(15, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_X_train[\"residual\"] = daily_X_train[\"Chiffre d'Affaires TTC\"] - daily_X_train[\"trend + seasonal\"]\n",
    "daily_X_train[\"Chiffre d'Affaires TTC\"] - daily_X_train[\"trend + seasonal\"]\n",
    "\n",
    "# daily_X_train[\"residual\"].plot(figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "cleaned_ar = AR(cleaned_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cleaned_ar.fit()\n",
    "# errors = pd.DataFrame(res).describe()\n",
    "print(res)\n",
    "res.k_ar\n",
    "# res.predict(res.params, start=datetime.now())\n",
    "daily_X_train.index[0], daily_X_train.index[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spectacle-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "## data organisation\n",
    "# each day:\n",
    "# * fetch ordered list of {spectacle, duration, start_date, type}\n",
    "# for each spectacle:\n",
    "# * \"chiffre d'affaire TTC\"\n",
    "# --------------------\n",
    "# for each spectacle predict \"chiffre d'affaire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ca(d):\n",
    "    cas = cleaned_daily[cleaned_daily.index == datetime(d.year, d.month, d.day)]\n",
    "    if len(cas) > 0:\n",
    "        return cas[0]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Chiffre d'Affaires TTC\"\n",
    "events[col] = events[\"DATE\"].apply(extract_ca)\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events[events[\"TYPE\"] != \"ko\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.boxplot(\"Chiffre d'Affaires TTC\", by=\"TYPE\", figsize=(15, 6), rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[events[\"TYPE\"] == \"concert\"].boxplot(\n",
    "    \"Chiffre d'Affaires TTC\", by=\"SUMMARY\", figsize=(15, 6), rot=90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.boxplot(\"Chiffre d'Affaires TTC\", by=\"DURATION\", figsize=(15, 6), rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.boxplot(\"Chiffre d'Affaires TTC\", by=\"START_TIME\", figsize=(15, 6), rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "inf_cols = [\"DURATION\", \"START_TIME\", \"TYPE\", \"Chiffre d'Affaires TTC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category encoding\n",
    "\n",
    "categs = events[\"TYPE\"].unique()\n",
    "# encode_categ_index = pd.MultiIndex.from_tuples(product([\"TYPE_ENCODE\"], categs))\n",
    "for categ in categs:\n",
    "    colname = \"TYPE_\" + categ\n",
    "    inf_cols.append(colname)\n",
    "    events[colname] = events[\"TYPE\"].apply(lambda x: 1 if x == categ else 0)\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to numerical\n",
    "events[\"DURATION\"] = events[\"DURATION\"].apply(lambda x: x.total_seconds())\n",
    "events[\"START_TIME\"] = events[\"START_TIME\"].apply(lambda x: x.hour * 60 + x.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_X_train, event_X_test = (\n",
    "    events[events[\"DATE\"] < split_date.date()],\n",
    "    events[events[\"DATE\"] >= split_date.date()],\n",
    ")\n",
    "event_X_train = event_X_train[inf_cols]\n",
    "event_X_train = event_X_train.dropna()\n",
    "\n",
    "event_X_test = event_X_test[inf_cols]\n",
    "event_X_test = event_X_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_X_train\n",
    "event_Y_train = event_X_train[\"Chiffre d'Affaires TTC\"]\n",
    "event_Y_test = event_X_test[\"Chiffre d'Affaires TTC\"]\n",
    "cols = [col for col in inf_cols if col not in (\"Chiffre d'Affaires TTC\", \"TYPE\")]\n",
    "event_X_train = event_X_train[cols]\n",
    "event_X_test = event_X_test[cols]\n",
    "\n",
    "event_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impr_reg = sklearn.linear_model.LinearRegression()\n",
    "impr_reg.fit(X=event_X_train, y=event_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\"predict\": impr_reg.predict(event_X_test), \"real\": event_Y_test}\n",
    ")\n",
    "results[\"error\"] = abs(results[\"predict\"] - results[\"real\"])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
